{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['네, 안녕하세요.', '반갑습니다.']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.utils import pprint\n",
    "\n",
    "kkma = Kkma()\n",
    "pprint(kkma.sentences(u'네,안녕하세요. 반갑습니다.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 3]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 0]\n",
      " [0 1 1 0 1 1]\n",
      " [0 0 1 1 0 0]\n",
      " [3 1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "docs = ['this this this book',\n",
    "       'this can good',\n",
    "       'cat good shit']\n",
    "\n",
    "count_model = CountVectorizer(ngram_range=(1,1))\n",
    "X = count_model.fit_transform(docs)\n",
    "\n",
    "Xc = (X.T * X)\n",
    "Xc.setdiag(0)\n",
    "\n",
    "print(Xc.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing sparse matrix:   (0, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (2, 1)\t1\n",
      "Printing dense matrix (cols are vocabulary keys 0-> \"awesome unicorns\", 1-> \"batman forever\") [[1 0]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "Sum of word-word occurrences: [[1 2]]\n",
      "Pretty printig of co_occurrences count: <zip object at 0x7f97ac351c48>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "samples = ['awesome unicorns are awesome','batman forever and ever','I love batman forever']\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2), vocabulary = {'awesome unicorns':0, 'batman forever':1}) \n",
    "co_occurrences = bigram_vectorizer.fit_transform(samples)\n",
    "print('Printing sparse matrix:', co_occurrences)\n",
    "print('Printing dense matrix (cols are vocabulary keys 0-> \"awesome unicorns\", 1-> \"batman forever\")', co_occurrences.todense())\n",
    "sum_occ = np.sum(co_occurrences.todense(),axis=0)\n",
    "print('Sum of word-word occurrences:', sum_occ)\n",
    "print('Pretty printig of co_occurrences count:', zip(bigram_vectorizer.get_feature_names(),np.array(sum_occ)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=1)\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "\n",
    "x = vectorizer.fit_transform(corpus)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "analyze(\"This is a text document to analyze.\") == (['this','is','text','document','to','analyze'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names() == (\n",
    "['and', 'document', 'first', 'is', 'one','second', 'the', 'third', 'this'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 3],\n",
       "       [0, 1, 0, 1, 0, 1],\n",
       "       [0, 0, 1, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
